{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK-Hynix Project Code - Pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SK-Hynix í”„ë¡œì íŠ¸ì—ì„œ ì§„í–‰í•œ ì—°êµ¬ì˜ ì‹¤í—˜ ì¤‘, encoder í•™ìŠµì½”ë“œë¥¼ ì •ë¦¬í•œ Jupyter notebook íŒŒì¼ì…ë‹ˆë‹¤.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####  1. 'Mixup ê¸°ë²•ìœ¼ë¡œ ì–»ì€ representationì„ contrastive taskì— ì‚¬ìš©í•˜ëŠ” ê²ƒ'ì´ ë³¸ ì—°êµ¬ì˜ í•µì‹¬ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### 2. í˜„ì¬ëŠ” [MoCo](https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdf) ë…¼ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì•„ì´ë””ì–´ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "#### 3. ì•„ì‰½ê²Œë„ multi-gpu ì‹¤í—˜ì€ í˜„ jupyter notebookì—ì„œëŠ” ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ê° í•¨ìˆ˜ë“¤ì˜ ê¸°ëŠ¥ë§Œ ë´ì£¼ì‹œë©´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic library setting\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os, math, random, time, shutil, builtins, argparse, warnings, json, glob\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Section 1] ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "#### CIFAR-10ê³¼ CIFAR-100 ë°ì´í„°ì˜ ê²½ìš°, torchvision.datasets libraryì—ì„œ ë°›ì•„ì˜µë‹ˆë‹¤.\n",
    "#### ë°˜ë©´ Tiny-ImageNet ì‹¤í—˜ì˜ ê²½ìš°, í˜„ directory ì•ˆì— data/tiny-imagenet-200 ì´ ì €ì¥ë˜ì–´ ìˆì–´ì•¼í•©ë‹ˆë‹¤. Tiny-ImageNet-200ì˜ ê²½ìš° [Tiny-ImageNet](https://tiny-imagenet.herokuapp.com/)ì—ì„œ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "### <span style=\"color:red\">Hynix ë°ì´í„°ì— ì ìš©í•˜ê¸° ìœ„í•´ì„  ë‹¤ìŒ ë‘ê°€ì§€ì˜ ì½”ë“œ êµ¬í˜„ì´ í•„ìš”í•´ë³´ì…ë‹ˆë‹¤.</span>\n",
    "- **pytorch libraryì˜ DataLoaderì— ë°ì´í„°ë¥¼ ì˜®ê¸°ëŠ” ì½”ë“œ**\n",
    "- **ë°ì´í„°ì— ë§ëŠ” augmentation ì½”ë“œ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10, CIFAR-100 dataset\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "\n",
    "\n",
    "# Tiny-ImageNet dataset\n",
    "EXTENSION = 'JPEG'\n",
    "NUM_IMAGES_PER_CLASS = 500\n",
    "CLASS_LIST_FILE = 'wnids.txt'\n",
    "VAL_ANNOTATION_FILE = 'val_annotations.txt'\n",
    "\n",
    "class TinyImageNet(Dataset):\n",
    "    \"\"\"Tiny ImageNet data set available from `http://cs231n.stanford.edu/tiny-imagenet-200.zip`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    root: string\n",
    "        Root directory including `train`, `test` and `val` subdirectories.\n",
    "    split: string\n",
    "        Indicating which split to return as a data set.\n",
    "        Valid option: [`train`, `test`, `val`]\n",
    "    transform: torchvision.transforms\n",
    "        A (series) of valid transformation(s).\n",
    "    in_memory: bool\n",
    "        Set to True if there is enough memory (about 5G) and want to minimize disk IO overhead.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, in_memory=False, download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.train = train\n",
    "        self.split = 'train' if train else 'val'\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.in_memory = in_memory\n",
    "        self.split_dir = os.path.join(root, self.split)\n",
    "        self.image_paths = sorted(glob.iglob(os.path.join(self.split_dir, '**', '*.%s' % EXTENSION), recursive=True))\n",
    "        self.labels = {}  # fname - label number mapping\n",
    "        self.images = []  # used for in-memory processing\n",
    "\n",
    "        # build class label - number mapping\n",
    "        with open(os.path.join(self.root, CLASS_LIST_FILE), 'r') as fp:\n",
    "            self.label_texts = sorted([text.strip() for text in fp.readlines()])\n",
    "        self.label_text_to_number = {text: i for i, text in enumerate(self.label_texts)}\n",
    "\n",
    "        if self.split == 'train':\n",
    "            for label_text, i in self.label_text_to_number.items():\n",
    "                for cnt in range(NUM_IMAGES_PER_CLASS):\n",
    "                    self.labels['%s_%d.%s' % (label_text, cnt, EXTENSION)] = i\n",
    "        elif self.split == 'val':\n",
    "            with open(os.path.join(self.split_dir, VAL_ANNOTATION_FILE), 'r') as fp:\n",
    "                for line in fp.readlines():\n",
    "                    terms = line.split('\\t')\n",
    "                    file_name, label_text = terms[0], terms[1]\n",
    "                    self.labels[file_name] = self.label_text_to_number[label_text]\n",
    "\n",
    "        # read all images into torch tensor in memory to minimize disk IO overhead\n",
    "        if self.in_memory:\n",
    "            self.images = [self.read_image(path) for path in self.image_paths]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.image_paths[index]\n",
    "\n",
    "        if self.in_memory:\n",
    "            img = self.images[index]\n",
    "        else:\n",
    "            img = self.read_image(file_path)\n",
    "\n",
    "        if self.split == 'test':\n",
    "            return img\n",
    "        else:\n",
    "            # file_name = file_path.split('/')[-1]\n",
    "            return img, self.labels[os.path.basename(file_path)]\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = self.split\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str\n",
    "\n",
    "    def read_image(self, path):\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        return self.transform(img) if self.transform else img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation ê´€ë ¨ ì½”ë“œì…ë‹ˆë‹¤.\n",
    "- ë‹¤ë¥¸ augmentationì´ ì ìš©ëœ queryì™€ keyë¥¼ ë½‘ê¸° ìœ„í•œ **TwoCropsTransform** ì½”ë“œ\n",
    "- MoCo ë°©ë²•ë¡ ì—ì„œ ì‚¬ìš©í–ˆë˜ **GaussianBlur**(SimCLR paperì—ì„œ ì‚¬ìš©í•œ ê²ƒì„ ì°¨ìš©) augmentation ì½”ë“œ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation\n",
    "class TwoCropsTransform:\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform):\n",
    "        self.base_transform = base_transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        q = self.base_transform(x)\n",
    "        k = self.base_transform(x)\n",
    "        return [q, k]\n",
    "\n",
    "\n",
    "class GaussianBlur(object):\n",
    "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
    "\n",
    "    def __init__(self, sigma=[.1, 2.]):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
    "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder í•™ìŠµì„ ìœ„í•´ ì„ íƒí•œ ë°ì´í„°ì…‹ì„ pytorch libraryì˜ DataLoaderë¡œ ì˜®ê¸°ëŠ” ì½”ë“œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "DATASETS = {'cifar10': CIFAR10, 'cifar100': CIFAR100, 'tiny-imagenet': TinyImageNet}\n",
    "MEAN = {'cifar10': [0.4914, 0.4822, 0.4465], 'cifar100': [0.5071, 0.4867, 0.4408], 'tiny-imagenet': [0.485, 0.456, 0.406]}\n",
    "STD = {'cifar10': [0.2023, 0.1994, 0.2010], 'cifar100':[0.2675, 0.2565, 0.2761], 'tiny-imagenet': [0.229, 0.224, 0.225]}\n",
    "\n",
    "def data_loader(dataset, data_path, batch_size, num_workers, download=False, distributed=True, aug_plus=True):\n",
    "    normalize = transforms.Normalize(MEAN[dataset], STD[dataset])\n",
    "\n",
    "    if aug_plus:\n",
    "        # MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709\n",
    "        augmentation = [\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "            ], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ]\n",
    "    else:\n",
    "        # MoCo v1's aug: the same as InstDisc https://arxiv.org/abs/1805.01978\n",
    "        augmentation = [\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ]\n",
    "\n",
    "    augmentation.insert(0, transforms.RandomResizedCrop(224, scale=(0.2, 1.)))\n",
    "\n",
    "    train_transform = TwoCropsTransform(transforms.Compose(augmentation))\n",
    "    train_dataset = DATASETS[dataset](data_path, train=True, download=download, transform=train_transform)\n",
    "\n",
    "    # for distributed learning\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset) if distributed else None\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=num_workers, pin_memory=True, sampler=train_sampler, drop_last=True)\n",
    "    \n",
    "    return train_loader, train_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Section 2] ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "#### MoCo ë°©ë²•ë¡ ì„ ê¸°ë°˜ìœ¼ë¡œ ì½”ë“œë¥¼ êµ¬í˜„í–ˆê³ , MoCoë‚˜ MixCoì— ê´€í•œ argument ì„¤ì •ì„ í†µí•´ ë‘ ë°©ë²•ë¡ ì„ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "#### Encoderì˜ ê¸°ë³¸ modelë¡œëŠ” ResNetì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "### <span style=\"color:red\">ë‹¤ì–‘í•œ ëª¨ë¸ ì ìš©ì„ ìœ„í•´ì„ , pytorchì— êµ¬í˜„ëœ ëª¨ë¸ ì½”ë“œë“¤ì„ ê°€ì ¸ì™€ ì‚¬ìš©í•˜ì‹œë©´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet code\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    __constants__ = ['downsample']\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1, \n",
    "                 base_width=64, dilation=1, norm_layer=None, num_splits=64, expansion=1, block_type='basic'):\n",
    "        super(Block, self).__init__()\n",
    "        if block_type not in ['basic', 'bottleneck']:\n",
    "            raise ValueError('Block_Type only supports basic and bottleneck')\n",
    "        self.block_type = block_type\n",
    "        self.expansion = expansion\n",
    "        \n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "            self.split = False\n",
    "        else:\n",
    "            self.split = True\n",
    "            \n",
    "        if block_type == 'basic':\n",
    "            if groups != 1 or base_width != 64:\n",
    "                raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "            if dilation > 1:\n",
    "                raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        \n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both conv3*3 with stride and self.downsample layers downsample the input when stride != 1\n",
    "        if block_type == 'basic':\n",
    "            self.conv1 = conv3x3(inplanes, width, stride)\n",
    "            self.conv2 = conv3x3(width, width)\n",
    "            \n",
    "        if block_type == 'bottleneck':\n",
    "            self.conv1 = conv1x1(inplanes, width)\n",
    "            self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "            self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "            self.bn3 = norm_layer(planes * self.expansion) if not self.split else norm_layer(planes * self.expansion, num_splits)\n",
    "            \n",
    "        self.bn1 = norm_layer(width) if not self.split else norm_layer(width, num_splits)\n",
    "        self.bn2 = norm_layer(width) if not self.split else norm_layer(width, num_splits)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.block_type == 'bottleneck':\n",
    "            out = self.relu(out)\n",
    "            \n",
    "            out = self.conv3(out)\n",
    "            out = self.bn3(out)\n",
    "            \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    BasicBlock_arch = ['resnet10', 'resnet18', 'resnet34']\n",
    "    Bottleneck_arch = ['resnet50', 'resnet101', 'resnet152', 'resnext50_32x4d', 'resnext101_32x8d', \n",
    "                      'wide_resnet50_2', 'wide_resnet101_2']\n",
    "\n",
    "    def __init__(self, arch, repeats, num_classes=100, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, norm_layer=None, num_splits=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.split = False if norm_layer is None else True\n",
    "        self._norm_layer = nn.BatchNorm2d if norm_layer is None else norm_layer\n",
    "        self.num_splits = num_splits\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        if arch in self.BasicBlock_arch:\n",
    "            self.expansion = 1\n",
    "            self.block_type = 'basic'\n",
    "        elif arch in self.Bottleneck_arch:\n",
    "            self.expansion = 4\n",
    "            self.block_type = 'bottleneck'\n",
    "        else:\n",
    "            raise NotImplementedError('%s arch is not supported in ResNet' % arch)\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False)\n",
    "        self.bn1 = self._norm_layer(self.inplanes) if not self.split else self._norm_layer(self.inplanes, self.num_splits)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)     \n",
    "            \n",
    "        planes = [64, 128, 256, 512]\n",
    "        # self.planes attributes is needed to match with EP_module channels\n",
    "        self.planes = [p * self.expansion for p in planes]\n",
    "        strides = [1, 2, 2, 2]\n",
    "        self.block_layers = self._make_layer(planes, repeats, strides)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(planes[-1] * self.expansion, num_classes)\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Block):\n",
    "                    if self.block_type == 'basic':\n",
    "                        nn.init.constant_(m.bn2.weight, 0)\n",
    "                    elif self.block_type == 'bottleneck':\n",
    "                        nn.init.constant_(m.bn3.weight, 0)\n",
    "                        \n",
    "    def _make_layer(self, planes, repeats, strides):\n",
    "        assert len(planes) == len(repeats) == len(strides) == 4, 'Number of Block should be 4'\n",
    "        \n",
    "        block_layers = []\n",
    "        norm_layer = self._norm_layer\n",
    "        for i in  range(4):\n",
    "            plane = planes[i]\n",
    "            repeat = repeats[i]\n",
    "            stride = strides[i]\n",
    "            \n",
    "            downsample = None\n",
    "            if stride != 1 or self.inplanes != plane * self.expansion:\n",
    "                if not self.split:\n",
    "                    downsample = nn.Sequential(\n",
    "                        conv1x1(self.inplanes, plane * self.expansion, stride),\n",
    "                        norm_layer(plane * self.expansion),\n",
    "                    )\n",
    "                else:\n",
    "                    downsample = nn.Sequential(\n",
    "                        conv1x1(self.inplanes, plane * self.expansion, stride),\n",
    "                        norm_layer(plane * self.expansion, self.num_splits),\n",
    "                    )\n",
    "\n",
    "            layers = []\n",
    "            layers.append(Block(self.inplanes, plane, stride, downsample, self.groups,\n",
    "                                self.base_width, self.dilation, norm_layer, self.num_splits,\n",
    "                                self.expansion, self.block_type))\n",
    "            self.inplanes = plane * self.expansion\n",
    "            for _ in range(1, repeat):\n",
    "                layers.append(Block(self.inplanes, plane, groups=self.groups,\n",
    "                                    base_width=self.base_width, dilation=self.dilation,\n",
    "                                    norm_layer=norm_layer, num_splits=self.num_splits,\n",
    "                                    expansion=self.expansion, block_type=self.block_type))\n",
    "            block_layers.append(nn.Sequential(*layers))\n",
    "        \n",
    "        return nn.Sequential(*block_layers)\n",
    "    \n",
    "    def conv_stem(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def pool_linear(self, x):\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_stem(x)\n",
    "        x = self.block_layers(x)\n",
    "        x = self.pool_linear(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def _resnet(arch, repeats, **kwargs):\n",
    "    model = ResNet(arch, repeats, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet10(**kwargs):\n",
    "    return _resnet('resnet10', [1, 1, 1, 1], **kwargs)    \n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    return _resnet('resnet18', [2, 2, 2, 2], **kwargs)\n",
    "\n",
    "\n",
    "def resnet34(**kwargs):\n",
    "    return _resnet('resnet34', [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    return _resnet('resnet50', [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "\n",
    "def resnet101( **kwargs):\n",
    "    return _resnet('resnet101', [3, 4, 23, 3], **kwargs)\n",
    "\n",
    "\n",
    "def resnet152(**kwargs):\n",
    "    return _resnet('resnet152', [3, 8, 36, 3], **kwargs)\n",
    "\n",
    "\n",
    "def resnet50_32x4d(**kwargs):\n",
    "    kwargs['groups'] = 32\n",
    "    kwargs['width_per_group'] = 4\n",
    "    return _resnet('resnet50_32x4d', [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "\n",
    "def resnet101_32x8d(**kwargs):\n",
    "    r\"\"\"ResNeXt-101 32x8d model from\n",
    "    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n",
    "    \"\"\"\n",
    "    kwargs['groups'] = 32\n",
    "    kwargs['width_per_group'] = 8\n",
    "    return _resnet('resnet101_32x8d', [3, 4, 23, 3], **kwargs)\n",
    "\n",
    "\n",
    "def wide_resnet50_2(**kwargs):\n",
    "    r\"\"\"Wide ResNet-50-2 model from\n",
    "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n",
    "    The model is the same as ResNet except for the bottleneck number of channels\n",
    "    which is twice larger in every block. The number of channels in outer 1x1\n",
    "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
    "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
    "    \"\"\"\n",
    "    kwargs['width_per_group'] = 64 * 2\n",
    "    return _resnet('wide_resnet50_2', [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "\n",
    "def wide_resnet101_2(**kwargs):\n",
    "    r\"\"\"Wide ResNet-101-2 model from\n",
    "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n",
    "    The model is the same as ResNet except for the bottleneck number of channels\n",
    "    which is twice larger in every block. The number of channels in outer 1x1\n",
    "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
    "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
    "    \"\"\"\n",
    "    kwargs['width_per_group'] = 64 * 2\n",
    "    return _resnet('wide_resnet101_2', [3, 4, 23, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have other architecture, type into ARCHITECTURE dict\n",
    "ARCHITECTURE = {'resnet10': resnet10, 'resnet18': resnet18, 'resnet34': resnet34, 'resnet50': resnet50}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MoCo ë…¼ë¬¸ì—ì„œ multi-gpu ìƒí™©ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ Batch Shufflingì´ë€ techniqueì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\n",
    "#### í•˜ì§€ë§Œ Single-gpuì—ì„œëŠ” shuffling ì ìš©ì´ ë¶ˆê°€í•´, encoderì—ì„œ ì‚¬ìš©í•˜ëŠ” BNì„ ë‹¤ìŒì˜ SplitBatchNormìœ¼ë¡œ ë°”ê¿€ ê²ƒì„ ê¶Œì¥í•˜ì˜€ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SplitBatchNorm: Same effect with Batch Shuffling in MoCo\n",
    "class SplitBatchNorm(nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, num_splits, **kw):\n",
    "        super().__init__(num_features, **kw)\n",
    "        self.num_splits = num_splits\n",
    "        \n",
    "    def forward(self, input):\n",
    "        N, C, H, W = input.shape\n",
    "        if self.training or not self.track_running_stats:\n",
    "            running_mean_split = self.running_mean.repeat(self.num_splits)\n",
    "            running_var_split = self.running_var.repeat(self.num_splits)\n",
    "            outcome = nn.functional.batch_norm(\n",
    "                input.view(-1, C * self.num_splits, H, W), running_mean_split, running_var_split, \n",
    "                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
    "                True, self.momentum, self.eps).view(N, C, H, W)\n",
    "            self.running_mean.data.copy_(running_mean_split.view(self.num_splits, C).mean(dim=0))\n",
    "            self.running_var.data.copy_(running_var_split.view(self.num_splits, C).mean(dim=0))\n",
    "            return outcome\n",
    "        else:\n",
    "            return nn.functional.batch_norm(\n",
    "                input, self.running_mean, self.running_var, \n",
    "                self.weight, self.bias, False, self.momentum, self.eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder classì˜ mixco argumentë¥¼ í†µí•´, MoCo ë°©ë²•ë¡ ê³¼ MixCo ë°©ë²•ë¡ ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a MoCo model with: a query encoder, a key encoder, and a queue\n",
    "    https://arxiv.org/abs/1911.05722\n",
    "    \"\"\"\n",
    "    def __init__(self, base_encoder, algo, dim=128, num_splits=64, K=65536, m=0.999, T=0.2, mix_T=0.05, mlp=False, single_gpu=False):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (default: 128)\n",
    "        K: queue size; number of negative keys (default: 65536)\n",
    "        m: moco momentum of updating key encoder (default: 0.999)\n",
    "        T: softmax temperature (default: 0.07)\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.algo = algo\n",
    "        self.single_gpu = single_gpu\n",
    "        \n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.mix_T = mix_T\n",
    "\n",
    "        # create the encoders\n",
    "        # num_classes is the output fc dimension\n",
    "        \n",
    "        norm_layer = SplitBatchNorm if single_gpu else None\n",
    "        self.encoder_q = base_encoder(num_classes=dim, norm_layer=norm_layer, num_splits=num_splits)\n",
    "        self.encoder_k = base_encoder(num_classes=dim, norm_layer=norm_layer, num_splits=num_splits)\n",
    "\n",
    "        if mlp:  # hack: brute-force replacement\n",
    "            dim_mlp = self.encoder_q.fc.weight.shape[1]\n",
    "            self.encoder_q.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_q.fc)\n",
    "            self.encoder_k.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_k.fc)\n",
    "\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient\n",
    "\n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def concat_all_gather(self, tensor):\n",
    "        \"\"\"\n",
    "        Performs all_gather operation on the provided tensors.\n",
    "        *** Warning ***: torch.distributed.all_gather has no gradient.\n",
    "        \"\"\"\n",
    "        tensors_gather = [torch.ones_like(tensor)\n",
    "            for _ in range(torch.distributed.get_world_size())]\n",
    "        torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "\n",
    "        output = torch.cat(tensors_gather, dim=0)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        # gather keys before updating queue\n",
    "        if not self.single_gpu:\n",
    "            keys = self.concat_all_gather(keys)\n",
    "\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.K % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.T\n",
    "        ptr = (ptr + batch_size) % self.K  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_ddp(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle, for making use of BatchNorm.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = self.concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(batch_size_all).cuda()\n",
    "\n",
    "        # broadcast to all gpus\n",
    "        torch.distributed.broadcast(idx_shuffle, src=0)\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        # shuffled index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this], idx_unshuffle\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_ddp(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = self.concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # restored index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this]\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def img_mixer(self, im_q):\n",
    "        B = im_q.size(0)\n",
    "        assert B % 2 == 0\n",
    "        sid = int(B/2)\n",
    "        im_q1, im_q2 = im_q[:sid], im_q[sid:]\n",
    "        \n",
    "        # each image get different lambda\n",
    "        lam = torch.from_numpy(np.random.uniform(0, 1, size=(sid,1,1,1))).float().to(im_q.device)\n",
    "        imgs_mix = lam * im_q1 + (1-lam) * im_q2\n",
    "        lbls_mix = torch.cat((torch.diag(lam.squeeze()), torch.diag((1-lam).squeeze())), dim=1)\n",
    "        \n",
    "        return imgs_mix, lbls_mix\n",
    "    \n",
    "    def forward(self, im_q, im_k):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            im_q: a batch of query images\n",
    "            im_k: a batch of key images\n",
    "        Output:\n",
    "            logits, targets\n",
    "        \"\"\"\n",
    "\n",
    "        if self.algo == 'moco':\n",
    "            q = self.encoder_q(im_q) # queries: NxC\n",
    "            q = nn.functional.normalize(q, dim=1)\n",
    "            \n",
    "        elif self.algo == 'mixco':\n",
    "            imgs_mix, lbls_mix = self.img_mixer(im_q)\n",
    "            # compute query features\n",
    "            q = self.encoder_q(torch.cat((im_q, imgs_mix))) # queries: NxC\n",
    "            q = nn.functional.normalize(q, dim=1)\n",
    "\n",
    "            q_mix = q[im_q.size(0):]\n",
    "            q = q[:im_q.size(0)]\n",
    "\n",
    "        # compute key features\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            self._momentum_update_key_encoder()  # update the key encoder\n",
    "\n",
    "            # shuffle for making use of BN\n",
    "            if not self.single_gpu:\n",
    "                im_k, idx_unshuffle = self._batch_shuffle_ddp(im_k)\n",
    "\n",
    "            k = self.encoder_k(im_k)  # keys: NxC\n",
    "            k = nn.functional.normalize(k, dim=1)\n",
    "\n",
    "            # undo shuffle\n",
    "            if not self.single_gpu:\n",
    "                k = self._batch_unshuffle_ddp(k, idx_unshuffle)\n",
    "            \n",
    "\n",
    "        # compute logits\n",
    "        # Einstein sum is more intuitive\n",
    "        # positive logits: Nx1\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
    "        # negative logits: NxK\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
    "\n",
    "        # logits: Nx(1+K)\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "        \n",
    "        if self.algo == 'moco':\n",
    "            # apply temperature\n",
    "            logits /= self.T\n",
    "\n",
    "            # dequeue and enqueue\n",
    "            self._dequeue_and_enqueue(k)\n",
    "\n",
    "            return logits, labels\n",
    "            \n",
    "        elif self.algo == 'mixco':\n",
    "            # mixed logits: N/2 x N\n",
    "            logits_mix_pos = torch.mm(q_mix, k.transpose(0, 1)) \n",
    "            # mixed negative logits: N/2 x K\n",
    "            logits_mix_neg = torch.mm(q_mix, self.queue.clone().detach())\n",
    "            logits_mix = torch.cat([logits_mix_pos, logits_mix_neg], dim=1) # N/2 x (N+K)\n",
    "            lbls_mix = torch.cat([lbls_mix, torch.zeros_like(logits_mix_neg)], dim=1)\n",
    "\n",
    "            # apply temperature\n",
    "            logits /= self.T\n",
    "            logits_mix /= self.mix_T\n",
    "\n",
    "            # dequeue and enqueue\n",
    "            self._dequeue_and_enqueue(k)\n",
    "\n",
    "            return logits, labels, logits_mix, lbls_mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Section 3] ì†ì‹¤í•¨ìˆ˜ ì •ì˜í•˜ê¸°\n",
    "\n",
    "#### Section 2ì˜ Encoderê°€ ë°˜í™˜í•´ì¤€ logitê³¼ labelì— ëŒ€í•´ì„œ, contrastive ì†ì‹¤ í•¨ìˆ˜ë¥¼ í†µí•´ ëª¨ë¸ì„ í•™ìŠµí•  ê²ƒì…ë‹ˆë‹¤.\n",
    "#### ê¸°ì¡´ì˜ MoCoì—ì„œ ì‚¬ìš©í•˜ëŠ” contrastive lossëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\\begin{equation*}\n",
    "L_{ğ‘€ğ‘œğ¶ğ‘œ}= -\\sum_{i=1}^n log(\\frac{exp(\\frac{v_i \\cdot v_{i}^{'}}{\\tau})}{\\sum_{j=0}^{r} exp(\\frac{v_i \\cdot v_{j}^{'}}{\\tau})})\n",
    "\\end{equation*}\n",
    "\n",
    "#### MixCo ë°©ë²•ë¡ ì˜ ê²½ìš°, ë‹¤ìŒì˜ ì†ì‹¤í•¨ìˆ˜ë¥¼ í†µí•´ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "\\begin{equation*}\n",
    "L_{MixCo}= L_{MoCo} + \\gamma * -(\\sum_{i=1}^n \\lambda_{i} * log(\\frac{exp(\\frac{v_{i}^{mix_{ij}} \\cdot v_{i}^{'}}{\\tau_{mix}})}{\\sum_{k=0}^{r} exp(\\frac{v_{i}^{mix_{ij}} \\cdot v_{k}^{'}}{\\tau_{mix}})}) + (1 - \\lambda_{i}) * log(\\frac{exp(\\frac{v_{i}^{mix_{ij}} \\cdot v_{j}^{'}}{\\tau_{mix}})}{\\sum_{k=0}^{r} exp(\\frac{v_{i}^{mix_{ij}} \\cdot v_{k}^{'}}{\\tau_{mix}})}))\n",
    "\\end{equation*}\n",
    "\n",
    "#### ië²ˆì§¸ ì´ë¯¸ì§€ì™€ jë²ˆì§¸ ì´ë¯¸ì§€ì˜ mixupìœ¼ë¡œ ì–»ì€ representationì— ëŒ€í•œ contrastive ì†ì‹¤í•¨ìˆ˜ë¥¼ ê¸°ì¡´ì˜ MoCo ì†ì‹¤í•¨ìˆ˜ì— ë”í•´ì£¼ëŠ” ë°©ë²•ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftCrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoftCrossEntropy, self).__init__()\n",
    "        \n",
    "    def forward(self, logits, target):\n",
    "        probs = F.softmax(logits, 1) \n",
    "        nll_loss = (- target * torch.log(probs)).sum(1).mean()\n",
    "\n",
    "        return nll_loss\n",
    "\n",
    "    \n",
    "class MixcoLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super(MixcoLoss, self).__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.soft_loss = SoftCrossEntropy()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, outputs):\n",
    "        if not self.gamma:\n",
    "            logits, labels = outputs\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "        else:\n",
    "            logits, labels, logits_mix, lbls_mix = outputs\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            loss += self.gamma * self.soft_loss(logits_mix, lbls_mix)\n",
    "        \n",
    "        return loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Section 4] í•™ìŠµ í•¨ìˆ˜ êµ¬í˜„í•˜ê¸°\n",
    "\n",
    "#### ë¨¼ì € í•™ìŠµ ê³¼ì •ì—ì„œ ì‚¬ìš©ë  seed ê³ ì •, learning_rate ì¡°ì ˆ, checkpoint ì €ì¥ ë“±ì˜ utils í•¨ìˆ˜ë“¤ì„ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤. \n",
    "#### ê·¸ ë‹¤ìŒ encoderì˜ í•œ epoch ë‹¨ìœ„ì˜ í•™ìŠµ í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def fix_seed(seed):\n",
    "    # fix seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "    warnings.warn('You have chosen to seed training. '\n",
    "                  'This will turn on the CUDNN deterministic setting, '\n",
    "                  'which can slow down your training considerably! '\n",
    "                  'You may see unexpected behavior when restarting '\n",
    "                  'from checkpoints.')\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='test'):\n",
    "    filename = os.path.join('./results/pretrained', filename)\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "    \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, lr, cos, num_epochs, schedule):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    lr = lr\n",
    "    if cos:  # cosine lr schedule\n",
    "        lr *= 0.5 * (1. + math.cos(math.pi * epoch / num_epochs))\n",
    "    else:  # stepwise lr schedule\n",
    "        for milestone in schedule:\n",
    "            lr *= 0.1 if epoch >= milestone else 1.\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "        \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "    \n",
    "    \n",
    "def update_json(exp_name, part='pretrain', acc=[0,0], path='./results/results.json'):\n",
    "    acc = [round(acc[0], 3), round(acc[1], 3)]\n",
    "    if not os.path.exists(path):\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump({}, f)\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        result_dict = json.load(f)\n",
    "    \n",
    "        if exp_name not in result_dict.keys():\n",
    "            result_dict[exp_name] = dict()\n",
    "\n",
    "        result_dict[exp_name][part] = acc\n",
    "    \n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(result_dict, f)\n",
    "        \n",
    "    print('results updated to %s' % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, criterion, epoch, print_freq, gpu):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if gpu is not None:\n",
    "            images[0] = images[0].cuda(gpu, non_blocking=True)\n",
    "            images[1] = images[1].cuda(gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(im_q=images[0], im_k=images[1])\n",
    "        loss = criterion(outputs)\n",
    "\n",
    "        # acc1/acc5 are (K+1)-way contrast classifier accuracy\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(outputs[0], outputs[1], topk=(1, 5))\n",
    "        losses.update(loss.item(), images[0].size(0))\n",
    "        top1.update(acc1[0], images[0].size(0))\n",
    "        top5.update(acc5[0], images[0].size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            progress.display(i)\n",
    "            \n",
    "    return top1.avg, top5.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Section 5] ë¶„ì‚°í•™ìŠµ í™˜ê²½ ì„¤ì •í•˜ê¸°\n",
    "\n",
    "#### ì´ì „ Sectionë“¤ì—ì„œ ì •ì˜í–ˆë˜ í•¨ìˆ˜ì™€ classë“¤ì„ ì´ìš©í•´, ì „ì²´ì ì¸ main_worker í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤. \n",
    "#### pytorchì—ì„œ ì œê³µí•˜ëŠ” ë¶„ì‚°í™˜ê²½ êµ¬ì¶• ì½”ë“œë¥¼ ì°¸ì¡°í•˜ì—¬ 'main' í•¨ìˆ˜ë¥¼ êµ¬í˜„ì˜€ìŠµë‹ˆë‹¤. 'func' argumentë¡œëŠ” 'main_worker' functionì„ ë„£ìœ¼ë©´ ë©ë‹ˆë‹¤. \n",
    "#### ì°¸ê³ ë¡œ, ë¶„ì‚°í™˜ê²½ì„ ì‚¬ìš©í•  ë•ŒëŠ” ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ê³¼ì •ì—ì„œ DistributedSamplerë¥¼ ì‚¬ìš©í•´ì•¼í•©ë‹ˆë‹¤. (Section 1 ì°¸ê³ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(gpu, ngpus_per_node, exp_name, distributed_kwargs, algo, arch, arch_kwargs, train_kwargs, data_kwargs):\n",
    "    gpu = gpu\n",
    "\n",
    "    # suppress printing if not master\n",
    "    if distributed_kwargs['multiprocessing_distributed'] and gpu != 0:\n",
    "        def print_pass(*args):\n",
    "            pass\n",
    "        builtins.print = print_pass\n",
    "\n",
    "    if gpu is not None:\n",
    "        print(gpu)\n",
    "        print(\"Use GPU: {} for training\".format(gpu))\n",
    "\n",
    "    if distributed_kwargs['distributed']:\n",
    "        if distributed_kwargs['dist_url'] == \"env://\" and distributed_kwargs['rank'] == -1:\n",
    "            rank = int(os.environ[\"RANK\"])\n",
    "        if distributed_kwargs['multiprocessing_distributed']:\n",
    "            # For multiprocessing distributed training, rank needs to be the\n",
    "            # global rank among all the processes\n",
    "            rank = rank * ngpus_per_node + gpu\n",
    "        dist.init_process_group(backend=distributed_kwargs['dist_backend'], \n",
    "                                init_method=distributed_kwargs['dist_url'],\n",
    "                                world_size=distributed_kwargs['world_size'],\n",
    "                                rank=rank)\n",
    "    # create model\n",
    "    print(\"=> creating model '{}'\".format(arch))\n",
    "    \n",
    "    model = Encoder(ARCHITECTURE[arch], algo, **arch_kwargs)\n",
    "    print(model)\n",
    "\n",
    "    if distributed_kwargs['distributed']:\n",
    "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "        # should always set the single device scope, otherwise,\n",
    "        # DistributedDataParallel will use all available devices.\n",
    "        if gpu is not None:\n",
    "            torch.cuda.set_device(gpu)\n",
    "            model.cuda(gpu)\n",
    "            # When using a single GPU per process and per\n",
    "            # DistributedDataParallel, we need to divide the batch size\n",
    "            # ourselves based on the total number of GPUs we have\n",
    "            data_kwargs['batch_size'] = int(data_kwargs['batch_size'] / ngpus_per_node)\n",
    "            data_kwargs['num_workers'] = int((data_kwargs['num_workers'] + ngpus_per_node - 1) / ngpus_per_node)\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[gpu])\n",
    "        else:\n",
    "            model.cuda()\n",
    "            # DistributedDataParallel will divide and allocate batch_size to all\n",
    "            # available GPUs if device_ids are not set\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    elif gpu is not None:\n",
    "        torch.cuda.set_device(gpu)\n",
    "        model = model.cuda(gpu)\n",
    "        \n",
    "    # define loss function (criterion) and optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), **train_kwargs['opt_kwargs'])\n",
    "    criterion = MixcoLoss(train_kwargs['gamma']).cuda(gpu)\n",
    "\n",
    "    # get train_loader\n",
    "    train_loader, train_sampler = data_loader(**data_kwargs)\n",
    "    \n",
    "    for epoch in range(train_kwargs['num_epochs']):\n",
    "        if distributed_kwargs['distributed']:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        adjust_learning_rate(optimizer, epoch, train_kwargs['opt_kwargs']['lr'], train_kwargs['cos'], train_kwargs['num_epochs'], train_kwargs['schedule'])\n",
    "\n",
    "        # train for one epoch\n",
    "        acc1, acc5 = train(train_loader, model, optimizer, criterion, epoch+1, train_kwargs['print_freq'], gpu)\n",
    "\n",
    "    # always saves at the end of training    \n",
    "    else:\n",
    "        if not distributed_kwargs['multiprocessing_distributed'] \\\n",
    "        or (distributed_kwargs['multiprocessing_distributed'] and rank % ngpus_per_node == 0):\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch+1,\n",
    "                'arch': arch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            }, is_best=False, filename='{}.pth.tar'.format(exp_name))\n",
    "            \n",
    "            update_json(exp_name, 'pretrain', [acc1.item(), acc5.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(func, exp_name, distributed_kwargs, algo, arch, arch_kwargs, train_kwargs, data_kwargs):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join([str(gpu) for gpu in distributed_kwargs['gpu']])\n",
    "    if len(distributed_kwargs['gpu']) > 1:\n",
    "        distributed_kwargs['gpu'] = None\n",
    "    else:\n",
    "        distributed_kwargs['gpu'] = [0]\n",
    "\n",
    "    if distributed_kwargs['gpu'] is not None:\n",
    "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                      'disable data parallelism.')\n",
    "\n",
    "    if distributed_kwargs['dist_url'] == \"env://\" and distributed_kwargs['world_size'] == -1:\n",
    "        distributed_kwargs['world_size'] = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    distributed_kwargs['distributed'] = distributed_kwargs['world_size'] > 1 or distributed_kwargs['multiprocessing_distributed']\n",
    "    distributed_kwargs['ngpus_per_node'] = torch.cuda.device_count()\n",
    "    \n",
    "    data_kwargs['distributed'] = distributed_kwargs['distributed']\n",
    "    \n",
    "    if distributed_kwargs['multiprocessing_distributed']:\n",
    "        # Since we have ngpus_per_node processes per node, the total world_size\n",
    "        # needs to be adjusted accordingly\n",
    "        distributed_kwargs['world_size'] *= distributed_kwargs['ngpus_per_node']\n",
    "        # Use torch.multiprocessing.spawn to launch distributed processes: the\n",
    "        # main_worker process function\n",
    "        mp.spawn(func, nprocs=distributed_kwargs['ngpus_per_node'], args=(distributed_kwargs['ngpus_per_node'], exp_name, distributed_kwargs, algo, arch, arch_kwargs, train_kwargs, data_kwargs))\n",
    "    else:\n",
    "        # Simply call main_worker function\n",
    "        func(distributed_kwargs['gpu'][0], distributed_kwargs['ngpus_per_node'], exp_name, distributed_kwargs, algo, arch, arch_kwargs, train_kwargs, data_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Section 6] Encoder í•™ìŠµí•˜ê¸°\n",
    "\n",
    "#### ResNet encoder ëª¨ë¸ì„ ë¼ë²¨ì´ ì—†ëŠ” Tiny-ImageNet ë°ì´í„°ë¥¼ ì´ìš©í•´ í•™ìŠµí•´ë³¼ ê²ƒì…ë‹ˆë‹¤.\n",
    "### <span style=\"color:red\">ì›í•˜ëŠ” ì‹¤í—˜ ì…‹íŒ…ì— í•„ìš”í•œ argumentë¥¼ ì •ì˜í•˜ì‹œë©´ ë©ë‹ˆë‹¤.</span>\n",
    "- ì•„ë˜ ì„¸íŒ…ì€ single-gpu ìƒí™©ì—ì„œ, mixco ë°©ë²•ë¡ ì˜ ì‹¤í—˜ì…ë‹ˆë‹¤.\n",
    "- **moco** ë°©ë²•ë¡ ìœ¼ë¡œ ì‹¤í—˜í•˜ë ¤ë©´, **train_kwargs['gamma'] = 0.0** ìœ¼ë¡œ ì„¤ì •í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "- **multiple-gpu** ìƒí™©ì—ì„œì˜ ì‹¤í—˜ì„ ì›í•˜ì‹œë©´, **distributed_kwargs['multiprocessing_distributed'] = True** ì™€ **distributed_kwargs['gpu'] = [gpu_number1, gpu_number2, ...]** ë¡œ ì„¤ì •í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "- <span style=\"color:red\">í•˜ì§€ë§Œ, jupyter notebookì—ì„œëŠ” multi-gpuë¥¼ ìœ„í•œ torch.multiprocessing.spawnì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ì—¬ê¸°ì„œëŠ” ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.<span style=\"color:red\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories\n",
    "!mkdir -p './results/pretrained'\n",
    "\n",
    "# setting\n",
    "seed = 0\n",
    "exp_name = 'mixco_resnet10'\n",
    "\n",
    "data_kwargs = {'dataset': 'tiny-imagenet',\n",
    "               'data_path': './data/tiny-imagenet-200',\n",
    "               'aug_plus': True,\n",
    "               'batch_size': 128,\n",
    "               'num_workers': 32,\n",
    "               'download': False}\n",
    "\n",
    "distributed_kwargs = {'multiprocessing_distributed': False,\n",
    "                      'dist_url': 'tcp://localhost:13311',\n",
    "                      'world_size': 1,\n",
    "                      'rank': 0,\n",
    "                      'dist_backend': 'nccl',\n",
    "                      'gpu': [0]}\n",
    "\n",
    "algo = 'mixco'\n",
    "arch = 'resnet10'\n",
    "arch_kwargs = {'dim': 128,\n",
    "               'K': 65536,\n",
    "               'm': 0.999,\n",
    "               'T': 0.2,\n",
    "               'mix_T': 0.05,\n",
    "               'mlp': True}\n",
    "arch_kwargs['single_gpu'] = False if len(distributed_kwargs['gpu']) > 1 else True\n",
    "arch_kwargs['num_splits'] = int(data_kwargs['batch_size']/2) if arch_kwargs['single_gpu'] else None\n",
    "\n",
    "train_kwargs = {'print_freq': 10,\n",
    "                'gamma': 1.0,\n",
    "                'num_epochs': 100,\n",
    "                'schedule': [60, 80],\n",
    "                'cos': True,\n",
    "                'opt_kwargs': {'lr': 0.015, 'momentum': 0.9, 'weight_decay': 1e-4}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Use GPU: 0 for training\n",
      "=> creating model 'resnet10'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangmin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.\n",
      "  if __name__ == '__main__':\n",
      "/home/sangmin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (encoder_q): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (block_layers): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Block(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (bn2): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Block(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (bn2): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Block(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): SplitBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (bn2): SplitBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): SplitBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Block(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): SplitBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (bn2): SplitBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): SplitBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder_k): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (block_layers): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Block(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (bn2): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Block(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (bn2): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Block(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): SplitBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (bn2): SplitBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): SplitBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Block(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): SplitBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (bn2): SplitBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): SplitBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Epoch: [1][  0/781]\tTime 12.686 (12.686)\tData  6.991 ( 6.991)\tLoss 1.1318e+01 (1.1318e+01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-efdd40e20aa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfix_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-388b6edac0b0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(func, exp_name, distributed_kwargs, algo, arch, arch_kwargs, train_kwargs, data_kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Simply call main_worker function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributed_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gpu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ngpus_per_node'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-dee3a06f01b1>\u001b[0m in \u001b[0;36mmain_worker\u001b[0;34m(gpu, ngpus_per_node, exp_name, distributed_kwargs, algo, arch, arch_kwargs, train_kwargs, data_kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0macc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'print_freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# always saves at the end of training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-67b95c693ea2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, optimizer, criterion, epoch, print_freq, gpu)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ba3eb8ce1c3a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, im_q, im_k)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# labels: positive key indicators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'moco'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fix_seed(seed)\n",
    "main(main_worker, exp_name, distributed_kwargs, algo, arch, arch_kwargs, train_kwargs, data_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
